---
title: Explainable AI
nextjs:
  metadata:
    title: Explainable AI
    description: TBD.
layout: plain
---
| Title                                                                                                                                         | Authors               | Venue                                                        | Year | Citations | Summary                                                                                                                                                                                                                                                                                                                                                  | Link |
|-----------------------------------------------------------------------------------------------------------------------------------------------|------------------------|---------------------------------------------------------------|------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|
| User Trust and Understanding of Explainable AI: Exploring Algorithm Visualisations and User Biases                                           | Dawn Branley-Bell +2  | Interacción                                                  | 2020 |        17 | The paper examines the impact of algorithm visualizations on user trust, comprehension, and biases in the context of explainable AI in healthcare.                                                                                                                                                                                                      | [ACM Digital Library](https://dl.acm.org/doi/abs/10.1007/978-3-030-49065-2_27) |
| The Effects of Automated Decision Algorithm Modality and Transparency on Reported Trust and Task Performance                                 | K. Oduor +1           | None                                                          | 2008 |        29 | Presenting the algorithm of an automated decision aid, in either textual or graphical format, impacts trust, usage, and performance.                                                                                                                                                                                                                      | [CoLab](https://colab.ws/articles/10.1177%2F154193120805200422) |
| Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders                                                 | H. Cheng +6           | International Conference on Human Factors in Computing Systems | 2019 |       298 | Interactive and "white-box" explanations can improve user comprehension of decision-making algorithms, but do not affect user trust.                                                                                                                                                                                                                      | [ACM Digital Library](https://dl.acm.org/doi/10.1145/3290605.3300789) |
| A Visual Analytics Approach to Understand Machine Learning Models in Healthcare                                                              | H. Strobelt +5        | IEEE Transactions on Visualization and Computer Graphics      | 2018 |       295 | Presents a system to interpret ML predictions and model behavior in healthcare using various visual interfaces, helping clinicians understand prediction pathways.                                                                                                                                                                                         |  |
| Opening the Black Box: Designing Transparent Interfaces for Machine Learning                                                                 | B. Kulesza +4         | ACM Transactions on Computer-Human Interaction                | 2013 |       839 | Investigates how the level of explanation detail and presentation format affect user mental models, trust, and satisfaction with machine learning systems.                                                                                                                                                                                                 |  |
| Interpretable Machine Learning: A Guide for Making Black Box Models Explainable                                                              | Christoph Molnar       | Book                                                          | 2022 |     11535 | A comprehensive guide covering various methods and tools for explaining black-box models, targeting data scientists and developers.                                                                                                                                                                                                                       | [Leanpub](https://leanpub.com/interpretable-machine-learning) |
| Design Patterns for Explainable Human-AI Interaction                                                                                          | Finale Doshi-Velez +7 | CHI Conference on Human Factors in Computing Systems          | 2020 |       571 | Proposes patterns and guidelines for designing explanations in human-AI interaction systems to improve understanding, trust, and usability.                                                                                                                                                                                                              |  |
| A Human-Centered Evaluation of a Visual Analytics System for Explainable Machine Learning                                                    | Jay Wang +3           | IEEE Transactions on Visualization and Computer Graphics      | 2019 |       219 | Evaluates a visual analytics system through human-centered experiments to explore how different explanation modalities affect user trust and decision making.                                                                                                                                                                                             |  |
| A Survey of Human-Centered Evaluations in Human-Agent Decision Making                                                                        | T. Yin +2             | ACM Computing Surveys                                          | 2022 |        70 | Provides a taxonomy and review of evaluation methodologies used in studies of human-agent decision-making, including explainability and trust.                                                                                                                                                                                                            |  |
| Trust Calibration in Human-AI Teams                                                                                                           | M. Zhang +3           | ACM Transactions on Interactive Intelligent Systems           | 2020 |        91 | Explores how trust calibration strategies (e.g., consistent AI performance, explanation frequency) impact human trust in AI teammates.                                                                                                                                                                                                                     |  |
| Communicating AI Capabilities and Limitations to Non-Experts: A Mental Model-Guided Approach                                                 | M. Abdul +3           | Conference on Human Factors in Computing Systems               | 2020 |       111 | Suggests using mental models to guide interface design for communicating the strengths and limitations of AI to lay users, improving trust and usability.                                                                                                                                                                                                 |  |
| Tracing and Communicating AI Decision Processes: Lessons from the Law                                                                        | A. Selbst +2          | Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society | 2021 |        84 | Draws on legal principles and precedents to suggest how AI systems can better trace and communicate their decision-making processes to users and regulators.                                                                                                                                                                                              |  |



## Explaining Unsupervised Learning to Different Audiences

| Audience       | Approach                           | Example                                       |
| -------------- | ---------------------------------- | --------------------------------------------- |
| General Public | Visual prototypes + analogies      | “These are normal heartbeats vs. odd ones”    |
| Policymakers   | Cluster summaries + decision trees | “Why a behavior was flagged as suspicious”    |
| Researchers    | SHAP, latent space visualizations  | “Feature-wise breakdown of model output”      |
| Journalists    | Temporal/visual explanations       | “How a person’s digital activity was flagged” |
| Students       | Interactive UMAP + labeling tools  | “Explore and annotate clusters”               |
